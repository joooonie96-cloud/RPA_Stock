# -*- coding: utf-8 -*-
# ë„¤ì´ë²„ ì¦ê¶Œ "ì™¸êµ­ì¸/ê¸°ê´€ Ã— ì½”ìŠ¤í”¼/ì½”ìŠ¤ë‹¥" ìˆœë§¤ìˆ˜ ìƒìœ„ í¬ë¡¤ë§ â†’ í…”ë ˆê·¸ë¨ ë°œì†¡
# ìš”êµ¬ì‚¬í•­ ë°˜ì˜:
#  - ë‚ ì§œ ê²€ì¦: div.sise_guide_date == ì˜¤ëŠ˜(YY.MM.DD), ë¶ˆì¼ì¹˜ì‹œ ì˜¤ë¥˜ ë©”ì‹œì§€ ì „ì†¡
#  - ì™¸êµ­ì¸/ê¸°ê´€ Ã— ì½”ìŠ¤í”¼/ì½”ìŠ¤ë‹¥ ì´ 80ì¢…ëª©(ê° 40) ìˆ˜ì§‘ ì—¬ë¶€ ì ê²€
#  - ì™¸êµ­ì¸ TOP25, ê¸°ê´€ TOP25ë¥¼ 'ê¸ˆì•¡(ë°±ë§Œ)' ê¸°ì¤€ìœ¼ë¡œ ë³„ë„ ì •ë ¬/ë°œì†¡
# í•„ìš” íŒ¨í‚¤ì§€: requests, beautifulsoup4
# pip install requests beautifulsoup4

import os, requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta, timezone

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í…”ë ˆê·¸ë¨ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BOT = os.getenv("BOT_TOKEN")
CHAT = os.getenv("CHAT_ID")
if not BOT or not CHAT:
    raise RuntimeError("í™˜ê²½ë³€ìˆ˜ BOT_TOKEN / CHAT_ID ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
TG_URL = f"https://api.telegram.org/bot{BOT}/sendMessage"

def send(msg: str):
    try:
        r = requests.post(TG_URL, data={"chat_id": CHAT, "text": msg}, timeout=20)
        r.raise_for_status()
    except Exception as e:
        print("í…”ë ˆê·¸ë¨ ì „ì†¡ ì‹¤íŒ¨:", e)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ HTTP í—¤ë” / ëŒ€ìƒ URL â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/115.0.0.0 Safari/537.36"
    ),
    "Referer": "https://finance.naver.com/",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
    "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
}

# ë„¤ì´ë²„ ì‹¤ì œ í™”ë©´ ë§¤í•‘(ì‚¬ìš©ì í™•ì¸ ê¸°ì¤€)
# key: í™”ë©´ ë¼ë²¨, value: (url, investor)  investorëŠ” "ì™¸êµ­ì¸" ë˜ëŠ” "ê¸°ê´€"
URLS = {
    "ê¸°ê´€(KOSPI)"  : ("https://finance.naver.com/sise/sise_deal_rank.naver?sosok=01&investor_gubun=1000", "ê¸°ê´€"),
    "ê¸°ê´€(KOSDAQ)" : ("https://finance.naver.com/sise/sise_deal_rank.naver?sosok=02&investor_gubun=1000", "ê¸°ê´€"),
    "ì™¸êµ­ì¸(KOSPI)": ("https://finance.naver.com/sise/sise_deal_rank.naver?sosok=01&investor_gubun=2000", "ì™¸êµ­ì¸"),
    "ì™¸êµ­ì¸(KOSDAQ)":("https://finance.naver.com/sise/sise_deal_rank.naver?sosok=02&investor_gubun=2000", "ì™¸êµ­ì¸"),
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ íŒŒì„œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def parse_page(url: str):
    """
    - ë‚ ì§œ ê²€ì¦: div.sise_guide_date == ì˜¤ëŠ˜(YY.MM.DD)
    - í‘œ íŒŒì‹±: table.type_2 ì˜ tbody > tr ì—ì„œ
        ì¢…ëª©ëª…: ì²« ë²ˆì§¸ td ë‚´ë¶€ì˜ p > a
        ê¸ˆì•¡  : ì„¸ ë²ˆì§¸ td (ë°±ë§Œ ë‹¨ìœ„, ì½¤ë§ˆ ì œê±° í›„ int, ìŒìˆ˜ í—ˆìš©)
    - ë°˜í™˜: [(name:str, amount:int)]
    """
    resp = requests.get(url, headers=HEADERS, timeout=20)
    if resp.status_code != 200:
        raise ValueError(f"HTTP ìƒíƒœì½”ë“œ {resp.status_code}")
    resp.encoding = "euc-kr"
    soup = BeautifulSoup(resp.text, "html.parser")

    # âœ… ë‚ ì§œ í™•ì¸ (YY.MM.DD, ì˜ˆ: 25.08.21)
    today = datetime.now(timezone(timedelta(hours=9))).strftime("%y.%m.%d")
    date_elem = soup.select_one("div.sise_guide_date")
    if not date_elem:
        snippet = resp.text[:200].replace("\n", " ")
        raise ValueError(f"ë‚ ì§œ element ì—†ìŒ(div.sise_guide_date). ì‘ë‹µ ì•ë¶€ë¶„: {snippet}")
    page_date = date_elem.get_text(strip=True)
    if page_date != today:
        raise ValueError(f"ë‚ ì§œ ë¶ˆì¼ì¹˜ (today={today}, page={page_date})")

    # âœ… í‘œ íŒŒì‹±
    table = soup.select_one("table.type_2")
    if not table:
        snippet = resp.text[:200].replace("\n", " ")
        raise ValueError(f"í…Œì´ë¸” ì—†ìŒ(table.type_2). ì‘ë‹µ ì•ë¶€ë¶„: {snippet}")

    data = []
    for tr in table.select("tbody > tr"):
        tds = tr.find_all("td")
        if len(tds) < 3:
            continue
        # ì¢…ëª©ëª…: ì²« ë²ˆì§¸ td > p > a
        name_tag = tds[0].select_one("p > a")
        # ê¸ˆì•¡: ì„¸ ë²ˆì§¸ td
        amt_tag  = tds[2]
        if not name_tag or not amt_tag:
            continue
        name = name_tag.get_text(strip=True)
        amt_str = amt_tag.get_text(strip=True).replace(",", "")
        # í—ˆìš©: ìŒìˆ˜("-123")ë„ int ë³€í™˜ ê°€ëŠ¥í•˜ê²Œ
        if not amt_str or not amt_str.replace("-", "").isdigit():
            continue
        amt = int(amt_str)
        data.append((name, amt))
    return data

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë©”ì¸ ë¡œì§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    kst = timezone(timedelta(hours=9))
    today_label = datetime.now(kst).strftime("%y.%m.%d")

    # ë„¤ ì„¹ì…˜ ìˆ˜ì§‘ + ì¹´í…Œê³ ë¦¬ ë¶„ë¦¬
    foreign = []  # ì™¸êµ­ì¸ (KOSPI+KOSDAQ)
    inst = []     # ê¸°ê´€   (KOSPI+KOSDAQ)

    total_count_check = 0
    for label, (url, investor) in URLS.items():
        try:
            rows = parse_page(url)  # [(name, amt)]
        except Exception as e:
            send(f"âŒ {label} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return

        total_count_check += len(rows)
        if investor == "ì™¸êµ­ì¸":
            foreign.extend(rows)
        else:
            inst.extend(rows)

    # 3) ì „ì²´ 80ì¢…ëª©(ì™¸êµ­ì¸40 + ê¸°ê´€40) ê²€ì¦
    if total_count_check != 80 or len(foreign) != 40 or len(inst) != 40:
        send(f"âŒ ì˜¤ë¥˜ë°œìƒ: ì¢…ëª© ìˆ˜ ë¶ˆì¼ì¹˜ (ì´={total_count_check}, ì™¸êµ­ì¸={len(foreign)}, ê¸°ê´€={len(inst)})")
        return

    # 4) ê¸ˆì•¡ ê¸°ì¤€ìœ¼ë¡œ ê° ì¹´í…Œê³ ë¦¬ ì •ë ¬ í›„ ìƒìœ„ 25
    top25_foreign = sorted(foreign, key=lambda x: x[1], reverse=True)[:25]
    top25_inst    = sorted(inst,    key=lambda x: x[1], reverse=True)[:25]

    # ë©”ì‹œì§€ ì¡°ë¦½
    lines = [f"ğŸ“ˆ {today_label} ì¥ë§ˆê° ìˆœë§¤ìˆ˜ ìƒìœ„ (ë„¤ì´ë²„ ì¦ê¶Œ)"]
    lines.append("")
    lines.append("ğŸ”¹ ì™¸êµ­ì¸ TOP25")
    for i, (name, amt) in enumerate(top25_foreign, 1):
        lines.append(f"{i}. {name} {amt:,}ë°±ë§Œ")
    lines.append("")
    lines.append("ğŸ”¹ ê¸°ê´€ TOP25")
    for i, (name, amt) in enumerate(top25_inst, 1):
        lines.append(f"{i}. {name} {amt:,}ë°±ë§Œ")

    send("\n".join(lines))

if __name__ == "__main__":
    main()
